{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ayesharahman1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ayesharahman1/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50/50 [==============================] - 13s 161ms/step - loss: 0.3895 - accuracy: 0.9078 - val_loss: 0.0672 - val_accuracy: 0.9850\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 10s 200ms/step - loss: 0.0258 - accuracy: 0.9944 - val_loss: 0.0097 - val_accuracy: 0.9987\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 10s 184ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 10s 210ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 12s 250ms/step - loss: 8.3811e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 13s 262ms/step - loss: 4.1810e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 13s 270ms/step - loss: 2.7748e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9987\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 15s 293ms/step - loss: 2.3466e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 14s 277ms/step - loss: 1.8762e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9987\n",
      "32/32 [==============================] - 2s 48ms/step\n",
      "Accuracy: 0.9980\n",
      "Precision: 1.0000\n",
      "Recall: 0.9959\n",
      "F1-Score: 0.9980\n",
      "INFO:tensorflow:Assets written to: ram://ba28d2ba-00d9-41b9-ab16-9fe483d9090c/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load dataset\n",
    "with open(\"synthetic_dataset_with_notes.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['processed_note'] = df['note'].apply(preprocess_text)\n",
    "\n",
    "# Tokenization and padding\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['processed_note'])\n",
    "sequences = tokenizer.texts_to_sequences(df['processed_note'])\n",
    "X = pad_sequences(sequences, maxlen=100)\n",
    "y = df['label'].values\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Definition\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=100),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Training\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=20, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluation\n",
    "predictions = model.predict(X_test)\n",
    "predictions = [1 if p > 0.5 else 0 for p in predictions]\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, predictions, average='binary')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-Score: {f1:.4f}')\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'autism_classifier.joblib')\n",
    "\n",
    "# Save the vectorizer\n",
    "joblib.dump(tokenizer, 'tfidf_vectorizer.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2371310abb41f4596ec457ca1e0992df68ce942553f6c0e8ef424c6dc23731f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('flask': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
